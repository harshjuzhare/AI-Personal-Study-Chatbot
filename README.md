#ğŸ¤– AI Study Assistant

AI Study Assistant is a full-stack web application that helps students learn smarter using Artificial Intelligence.  
It uses a **local AI model (Mistral via Ollama)** to generate responses without using any paid API.

---

## ğŸš€ Features

- ğŸ’¬ AI Chat Assistant (Ask study doubts)
- ğŸ“„ File Upload & AI Explanation
- ğŸ“ Notes Management (UI ready)
- â“ Quiz Section (UI ready)
- ğŸ¨ Modern Animated Dashboard
- âš¡ Fully Local AI (No OpenAI API Required)

---

## ğŸ›  Tech Stack

### Frontend
- React (Vite)
- Tailwind CSS
- React Router
- Framer Motion

### Backend
- Node.js
- Express.js
- Axios
- Multer (File Upload)

### AI Engine
- Ollama (Local LLM Runtime)
- Mistral Model

---

## ğŸ“‚ Project Structure


AI-Study-Assistant/
â”‚
â”œâ”€â”€ backend/
â”‚ â”œâ”€â”€ routes/
â”‚ â”œâ”€â”€ uploads/
â”‚ â”œâ”€â”€ server.js
â”‚ â””â”€â”€ package.json
â”‚
â”œâ”€â”€ frontend/
â”‚ â”œâ”€â”€ src/
â”‚ â”‚ â”œâ”€â”€ components/
â”‚ â”‚ â”œâ”€â”€ pages/
â”‚ â”‚ â”œâ”€â”€ App.jsx
â”‚ â”‚ â””â”€â”€ main.jsx
â”‚ â””â”€â”€ package.json
â”‚
â””â”€â”€ README.md


---

## âš™ï¸ Installation & Setup

### 1ï¸âƒ£ Install Ollama

Download from:  
https://ollama.com

Then install Mistral model:


ollama pull mistral


---

### 2ï¸âƒ£ Start Ollama


ollama run mistral


After it loads, press **Ctrl + C**  
(Ollama server keeps running in background)

---

### 3ï¸âƒ£ Start Backend


cd backend
npm install
node server.js


Backend runs on:


http://localhost:5000


---

### 4ï¸âƒ£ Start Frontend

Open new terminal:


cd frontend
npm install
npm run dev


Frontend runs on:


http://localhost:5173


---

## ğŸ”— API Endpoints

### Chat API

POST /api/chat


Request Body:
```json
{
  "message": "Explain recursion simply"
}
File Upload API
POST /api/upload

FormData:

file: <your_text_file>
